{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Sparseloop Tutorial - 02 - Matrix Multiply\n",
    "\n",
    "This notebook contains a series of examples of a **matrix multiply** computation. The **fibertree** emulator is used to illustrate the impact of a set of optimizations to exploit sparsity. The basic computation is represented by the Einsum:\n",
    "\n",
    "$$ Z_{m,n} = A_{m,k} \\times B_{k,n} $$\n",
    "\n",
    "Note that while the output is nominally a sparse rank-2 tensor, in this notebook the output is assumed to be in an uncompressed format and is directly referenced by **coordinate** since **position** == **coordinate** in an uncompressed format.\n",
    "\n",
    "First, include some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "\n",
    "%run ./prelude.py --style=tree --animation=movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure two rank-2 input tensors\n",
    "\n",
    "The following cell sets up the control sliders to specify the attributes of the `A` and `B` input tensors. Those attributes include their **shape**, which specifies the allowable range of **coordinates** of elements of the tensor and their **density**.\n",
    "\n",
    "The rank names use the following convention:\n",
    "\n",
    "- M - uncontracted dimension in input `A`\n",
    "- N - uncontracted dimension in input `B`\n",
    "- K - contracted dimension shared by `A` and `B`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Set default problem instance attributes (i.e., the shape of the tensors)\n",
    "#\n",
    "K = 8\n",
    "M = 6\n",
    "N = 6\n",
    "\n",
    "#\n",
    "# Create controls to configure the `A` and `B` tensors\n",
    "#\n",
    "tm2 = TensorMaker(\"sparseloop-matrix-multiply\", autoload=True)\n",
    "\n",
    "tm2.addTensor(\"A\", rank_ids=[\"M\", \"K\"], shape=[M, K], density=0.4, color=\"blue\")\n",
    "tm2.addTensor(\"B\", rank_ids=[\"K\", \"N\"], shape=[K, N], density=0.5, color=\"green\")\n",
    "\n",
    "tm2.displayControls()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and display the input tensors\n",
    "\n",
    "Create the `A` and `B` tensors based on the current settings of the configuration sliders above and display the resulting tensors. These tensors are represented in the **fibertree** tensor abstraction, where for sparse fibers only the **elements** (**coordinate**/**payload** tuples) in a fiber with **non-empty** (non-zero) payloads need be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_MK = tm2.makeTensor(\"A\")\n",
    "B_KN = tm2.makeTensor(\"B\")\n",
    "\n",
    "displayTensor(A_MK)\n",
    "displayTensor(B_KN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traverse a rank-2 tensor\n",
    "\n",
    "As a simple illustration of the traversal of a rank-2 tensor, the following code shows how that can be accomplished with two nested `for` loops where the **payload** of the traversal of the top rank is a reference to a **fiber** in the next rank.\n",
    "\n",
    "This natural traversal order where the bottom rank is traversed fastest (i.e., in a depth first fashion) is referred to as a **concordant** traversal and tend to be the most efficient. Other, less efficient, traversal orders are referred to as **discordant**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create a rank-2 tensor\n",
    "#\n",
    "A_MK = tm2.makeTensor(\"A\")\n",
    "\n",
    "#\n",
    "# Get root of tensor\n",
    "#\n",
    "a_m = A_MK.getRoot()\n",
    "\n",
    "#\n",
    "# Animation bookkeeeping\n",
    "#\n",
    "canvas = createCanvas(A_MK)\n",
    "\n",
    "cycle = 0\n",
    "\n",
    "#\n",
    "# Traverse non-empty elements of top rank\n",
    "#\n",
    "for m, a_k in a_m:\n",
    "    #\n",
    "    # Traverse non-empty element of bottom rank\n",
    "    #\n",
    "    for k, a_val in a_k:\n",
    "        \n",
    "        print(f\"{a_val} \", end='')\n",
    "            \n",
    "        #\n",
    "        # Animation bookkeeping\n",
    "        #\n",
    "        canvas.addActivity((m,k), spacetime=(0,cycle))\n",
    "        cycle += 1\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix multiply\n",
    "\n",
    "The following code illustrates the traversal and accesses associated with the computation of untiled matrix multiply as expressed by the following Einsum:\n",
    "\n",
    "$$ Z_{m,n} = A_{m,k} \\times B_{k,n} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Create the input/output tensors\n",
    "#\n",
    "K = getShape(tm2, \"K\")\n",
    "M = getShape(tm2, \"M\")\n",
    "N = getShape(tm2, \"N\")\n",
    "\n",
    "A_MK = tm2.makeTensor(\"A\")\n",
    "B_KN = tm2.makeTensor(\"B\")\n",
    "\n",
    "Z_MN = Tensor(name=\"Z\", rank_ids=[\"M\", \"N\"], shape=[M, N])\n",
    "\n",
    "uncompressTensor(Z_MN)\n",
    "\n",
    "#\n",
    "# Display the tensors\n",
    "#\n",
    "print(\"Problem instance:\")\n",
    "print(f\"M: {M}\")\n",
    "print(f\"K: {K}\")\n",
    "print(f\"N: {N}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Input A\")\n",
    "displayTensor(A_MK)\n",
    "print(\"Input B\")\n",
    "displayTensor(B_KN)\n",
    "print(\"Output Z (initial)\")\n",
    "displayTensor(Z_MN)\n",
    "\n",
    "#\n",
    "# Get the root fibers of each tensor\n",
    "#\n",
    "a_m = A_MK.getRoot()\n",
    "b_k = B_KN.getRoot()\n",
    "z_m = Z_MN.getRoot()\n",
    "\n",
    "#\n",
    "# Animation bookkeeping\n",
    "#\n",
    "canvas = createCanvas(A_MK, B_KN, Z_MN)\n",
    "\n",
    "cycle = 0\n",
    "\n",
    "#\n",
    "# Traverse non-empty elements of top rank of `A`\n",
    "#\n",
    "for m, a_k in a_m:\n",
    "    #\n",
    "    # Traverse the K rank of `A`\n",
    "    #\n",
    "    for k, a_val in a_k:\n",
    "        #\n",
    "        # Obtain the matching fiber in `B`\n",
    "        #\n",
    "        b_n = b_k.getPayload(k)\n",
    "        \n",
    "        #\n",
    "        # Traverse the bottom rank of `B`\n",
    "        #\n",
    "        for n, b_val in b_n:\n",
    "            #\n",
    "            # Do the reduction\n",
    "            #\n",
    "            z_m[m][n] += a_val * b_val\n",
    "            \n",
    "            #\n",
    "            # Animation bookkeeping\n",
    "            #\n",
    "            canvas.addActivity((m,k), (k,n), (m, n), spacetime=(0,cycle))\n",
    "            cycle += 1\n",
    "            \n",
    "#\n",
    "# Display results\n",
    "#\n",
    "print(\"Output tensor Z (final)\")\n",
    "displayTensor(Z_MN)\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiled Matrix Multiply\n",
    "\n",
    "$$ Z_{n1,m,n0} = A_{m,k} \\times B_{n1,k,n0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of B\n",
    "\n",
    "First we look at the sequence for splitting the `B` tensor along the N rank.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The coordinates in the N0 rank are the original N coordinates\n",
    "- We are assuming that this is done offline... Online tiling is beyond the scope of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create tensors\n",
    "#\n",
    "\n",
    "N0 = 3\n",
    "\n",
    "B_KN = tm2.makeTensor(\"B\")\n",
    "\n",
    "print(\"Original B tensor\")\n",
    "displayTensor(B_KN)\n",
    "\n",
    "#\n",
    "# Split the `N` rank of `B` into a series of fibers with shape `N0`\n",
    "# then rename the coordinates of the N1 rank to match the coordinates we want in the output (hacky)\n",
    "#\n",
    "B_N1N0K = B_KN.splitUniform(N0, depth=1)\n",
    "B_N1N0K = B_N1N0K.updateCoords(lambda n, c, p: n, depth=1)\n",
    "\n",
    "print(\"B tensor with N rank split into fibers with a shape={N0}\")\n",
    "displayTensor(B_N1N0K)\n",
    "\n",
    "#\n",
    "# Swizzle the ranks of B so that we can traverse it in a **concordant** fashion\n",
    "#\n",
    "B_N1KN0 = B_N1N0K.swapRanks()\n",
    "\n",
    "print(\"B tensor split and swizzed for concordant traversal\")\n",
    "displayTensor(B_N1KN0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiled Matrix Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Create the input/output tensors\n",
    "#\n",
    "K = getShape(tm2, \"K\")\n",
    "M = getShape(tm2, \"M\")\n",
    "N = getShape(tm2, \"N\")\n",
    "\n",
    "N1 = 2\n",
    "N0 = (N+1)//2\n",
    "\n",
    "#\n",
    "# Create tensors\n",
    "#\n",
    "\n",
    "A_MK = tm2.makeTensor(\"A\")\n",
    "B_KN = tm2.makeTensor(\"B\")\n",
    "\n",
    "\n",
    "B_N1KN0 = B_KN.splitUniform(N0, depth=1).swapRanks()\n",
    "B_N1KN0 = B_N1KN0.updateCoords(lambda n, c, p: n)\n",
    "\n",
    "Z_MN = Tensor(name=\"Z\",\n",
    "              rank_ids=[\"M\", \"N\"],\n",
    "                 shape=[M, N])\n",
    "uncompressTensor(Z_MN)\n",
    "\n",
    "Z_N1MN0 = Z_MN.splitUniform(N0, depth=1).swapRanks()\n",
    "Z_N1MN0 = Z_N1MN0.updateCoords(lambda n, c, p: n)\n",
    "Z_N1MN0.setMutable(True)\n",
    "\n",
    "#\n",
    "# Display Tensors\n",
    "#\n",
    "print(\"Problem instance:\")\n",
    "print(f\"K:  {K}\")\n",
    "print(f\"M:  {M}\")\n",
    "print(f\"N:  {N}\")\n",
    "print(f\"N1: {N1}\")\n",
    "print(f\"N0: {N0}\")\n",
    "\n",
    "displayTensor(A_MK)\n",
    "displayTensor(B_N1KN0)\n",
    "displayTensor(Z_N1MN0)\n",
    "\n",
    "#\n",
    "# Get the root fibers of each tensor\n",
    "#\n",
    "a_m = A_MK.getRoot()\n",
    "b_n1 = B_N1KN0.getRoot()\n",
    "z_n1 = Z_N1MN0.getRoot()\n",
    "\n",
    "#\n",
    "# Animation bookkeeping\n",
    "#\n",
    "canvas = createCanvas(A_MK, B_N1KN0, Z_N1MN0)\n",
    "\n",
    "cycle = 0\n",
    "\n",
    "#\n",
    "# Traverse non-empty elements of `N1` (top) rank of `B`\n",
    "#\n",
    "for n1, b_k in b_n1:\n",
    "    #\n",
    "    # Traverse non-empty elements of `M` (top) rank of A\n",
    "    #\n",
    "    for m, a_k in a_m:\n",
    "        #\n",
    "        # Traverse the K (bottom) rank of `A`\n",
    "        #\n",
    "        for k, a_val in a_k:\n",
    "            #\n",
    "            # Obtain the matching fiber in `B`\n",
    "            #\n",
    "            b_n0 = b_k.getPayload(k)\n",
    "        \n",
    "            #\n",
    "            # Traverse the `N0` (bottom) rank of `B`\n",
    "            #\n",
    "            for n0, b_val in b_n0:\n",
    "                #\n",
    "                # Do the reduction\n",
    "                #\n",
    "                # Note hack to get right position in `N0` rank of `Z`\n",
    "                #\n",
    "                z_n1[n1][m][n0%N0] += a_val * b_val\n",
    "            \n",
    "                #\n",
    "                # Animation bookkeeping\n",
    "                #\n",
    "                canvas.addActivity([(m,k)], [(n1,k,n0)], [(n1, m, n0)], \n",
    "                                   spacetime=(0,cycle))\n",
    "                cycle += 1\n",
    "            \n",
    "displayTensor(Z_N1MN0)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area\n",
    "\n",
    "For running alternative algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
