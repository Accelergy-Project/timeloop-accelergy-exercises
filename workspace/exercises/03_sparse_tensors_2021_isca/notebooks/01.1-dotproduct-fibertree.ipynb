{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Sparseloop Tutorial - 01 - Dot Product\n",
    "\n",
    "This notebook contains a series of examples of a **dot product** computation, i.e., a reduction of the element-wise products of all the elements of the inputs. The **fibertree** emulator is used to illustrate the impact of a set of optimizations to exploit sparsity. The basic computation is represented by the Einsum:\n",
    "\n",
    "$$ Z_m = A_k \\times B_k $$\n",
    "\n",
    "Note that while the output is nominally a scalar, for consistency with the **Timeloop** tool the output implemented as a 1-D tensor. However, that tensor contains only a single element.\n",
    "\n",
    "First, include some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "\n",
    "%run ./prelude.py --style=tree --animation=movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure two rank-1 input tensors\n",
    "\n",
    "The following cell sets up the control sliders to specify the attributes of the `A` and `B` input tensors. Those attributes include their **shape**, which specifies the allowable range of **coordinates** of elements of the tensor and their **density**.\n",
    "\n",
    "The rank names use the following convention:\n",
    "\n",
    "- K - contracted dimension shared by `A` and `B`\n",
    "- M - dummy rank for output `Z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Set default problem instance attributes (i.e., the shape of the tensors)\n",
    "#\n",
    "K = 10\n",
    "M = 1\n",
    "\n",
    "#\n",
    "# Create controls to configure the `A` and `B` tensors\n",
    "#\n",
    "tm = TensorMaker(\"sparseloop-dot-product\")\n",
    "\n",
    "tm.addTensor(\"A\", rank_ids=[\"K\"], shape=[K], density=0.4, color=\"blue\")\n",
    "tm.addTensor(\"B\", rank_ids=[\"K\"], shape=[K], density=1.0, color=\"green\")\n",
    "\n",
    "tm.displayControls()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and display the tensors\n",
    "\n",
    "Create the `A` and `B` tensors based on the current settings of the configuration sliders above and display the resulting tensors. These tensors are represented in the **fibertree** tensor abstraction, where for sparse fibers only the **elements** (**coordinate**/**payload** tuples) in a fiber with **non-empty** (non-zero) payloads need be shown.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A_K = tm.makeTensor(\"A\")\n",
    "B_K = tm.makeTensor(\"B\")\n",
    "\n",
    "displayTensor(A_K)\n",
    "displayTensor(B_K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dot product - A, B uncompressed\n",
    "\n",
    "The following code sequence corresponds to an implementation of dot product where the hardware must read every **coordinate** of each input tensor and reduces the element-wise products of those values into the output irrespective of whether any **payload** value is zero. This corresponds to the totally unoptimized case.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The code below uses the `Fiber.getPayload()` method to obtain a **payload** value by **coordinate**. For `A` and `B` in an **uncompressed** format this is a cheap direct access because the **coordinate** equals the **position** of the value, but the operation could be much more expensive for other formats.\n",
    "\n",
    "- To force a useful visualization of the traversal of the `A` tensor it's **empty** coordinates are filled with zeros using the `uncompressTensor()` method.\n",
    "\n",
    "- The code below assumes that the output tensor `Z` is in an uncompressed format. Again this is facilitated with the `uncompressTensor()` method and allows updates to be performed with direct indexing into the output tensor by **coordinate** (again because for uncompressed formats the **coordinate** and **position** are equal).\n",
    "\n",
    "Observations:\n",
    "\n",
    "- The computation takes `K` cycles irrespective of the sparsity of the the input tensors.\n",
    "\n",
    "- The hardware reads a value from both tensors irrespective of whether a **payload** value in `A` is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Create the input/output tensors\n",
    "#\n",
    "K = getShape(tm, \"K\")\n",
    "M = 1\n",
    "\n",
    "A_K = tm.makeTensor(\"A\")\n",
    "B_K = tm.makeTensor(\"B\")\n",
    "Z_M = Tensor(name=\"Z\", rank_ids=[\"M\"], shape=[M])\n",
    "\n",
    "uncompressTensor(A_K)\n",
    "uncompressTensor(Z_M)\n",
    "\n",
    "#\n",
    "# Display the input tensors\n",
    "#\n",
    "print(\"Problem instance:\")\n",
    "print(f\"K: {K}\")\n",
    "print(f\"M: {M}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Input tensor A\")\n",
    "displayTensor(A_K)\n",
    "print(\"Input tensor B\")\n",
    "displayTensor(B_K)\n",
    "print(\"Output tensor Z (intial)\")\n",
    "displayTensor(Z_M)\n",
    "\n",
    "#\n",
    "# Get the root fibers of each tensor\n",
    "#\n",
    "a_k = A_K.getRoot()\n",
    "b_k = B_K.getRoot()\n",
    "z_m = Z_M.getRoot()\n",
    "\n",
    "#\n",
    "# Animation bookkeeping\n",
    "#\n",
    "canvas = createCanvas(A_K, B_K, Z_M)\n",
    "\n",
    "#\n",
    "# Traverse all `M` coordinates of the output tensor\n",
    "#\n",
    "for m in range(M):\n",
    "\n",
    "    #\n",
    "    # Traverse all `K` coordinates of the input tensors\n",
    "    #\n",
    "    for k in range(K):\n",
    "        #\n",
    "        # Get the values of `A` and `B` at coordinate `k`\n",
    "        #\n",
    "        a_val = a_k.getPayload(k)\n",
    "        b_val = b_k.getPayload(k)\n",
    "    \n",
    "        #\n",
    "        # Do the dot product multiplication and reduction\n",
    "        #\n",
    "        z_m[m] += a_val * b_val\n",
    "    \n",
    "        #\n",
    "        # Animation bookkeeping\n",
    "        #\n",
    "        canvas.addActivity([(k,)], [(k,)], [(m,)],\n",
    "                           spacetime=(0, k))\n",
    "    \n",
    "    \n",
    "#\n",
    "# Display results\n",
    "#\n",
    "print(\"Output tensor Z (final)\")\n",
    "displayTensor(Z_M)\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dot Product - Gating Unneeded Reads\n",
    "\n",
    "The following code sequence corresponds to an implementation of dot product where the hardware must read every **coordinate** of the input tensor `A` but then **gates** the read of `B` and computation when the **payload** value of an element of tensor `A` is zero. This corresponds to the case where `B` is gated on `A`.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The code below again uses the `Fiber.getPayload()` method to obtain a **payload** value by **coordinate** for both the `A` and `B` tensors. \n",
    "\n",
    "- The cost of the reference to `A` may vary based on whether the specific format needs to do an access for **coordinates** with zero values.\n",
    "\n",
    "- As in the case above, the code in this cell assumes that the output tensor `Z` is in an uncompressed format.\n",
    "\n",
    "Observations:\n",
    "\n",
    "- The computation takes `K` cycles irrespective of the sparsity of the the input tensors\n",
    "\n",
    "- The hardware saves reads of data and computation when the **payload** value of `A` is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Create the input/output tensors\n",
    "#\n",
    "K = getShape(tm, \"K\")\n",
    "M = 1\n",
    "\n",
    "A_K = tm.makeTensor(\"A\")\n",
    "B_K = tm.makeTensor(\"B\")\n",
    "Z_M = Tensor(name=\"Z\", rank_ids=[\"M\"], shape=[M])\n",
    "\n",
    "uncompressTensor(A_K)\n",
    "uncompressTensor(Z_M)\n",
    "\n",
    "#\n",
    "# Display the input tensors\n",
    "#\n",
    "print(\"Problem instance:\")\n",
    "print(f\"K: {K}\")\n",
    "print(f\"M: {M}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Input A\")\n",
    "displayTensor(A_K)\n",
    "print(\"Input B\")\n",
    "displayTensor(B_K)\n",
    "print(\"Output Z (initial)\")\n",
    "displayTensor(Z_M)\n",
    "\n",
    "#\n",
    "# Get the root fibers of each tensor\n",
    "#\n",
    "a_k = A_K.getRoot()\n",
    "b_k = B_K.getRoot()\n",
    "z_m = Z_M.getRoot()\n",
    "\n",
    "#\n",
    "# Animation bookkeeping\n",
    "#\n",
    "canvas = createCanvas(A_K, B_K, Z_M)\n",
    "\n",
    "#\n",
    "# Traverse the single element of the output shape\n",
    "#\n",
    "for m in range(M):\n",
    "    #\n",
    "    # Traverse all `K` coordinates of the input tensor `A`\n",
    "    #\n",
    "    for k in range(K):\n",
    "        #\n",
    "        # Get the value of `A` at coordinate `k`\n",
    "        #\n",
    "        a_val = a_k.getPayload(k)\n",
    "    \n",
    "        #\n",
    "        # Gate the access to the value of `B`\n",
    "        # and computation based on the value of `A`\n",
    "        #\n",
    "        if a_val != 0:\n",
    "            b_val = b_k.getPayload(k)\n",
    "\n",
    "            z_m[m] += a_val * b_val\n",
    "\n",
    "        #\n",
    "        # Animation bookkeeping\n",
    "        #\n",
    "        if a_val == 0:\n",
    "            B_activity = []\n",
    "            Z_activity = []\n",
    "        else:\n",
    "            B_activity = [(k,)]\n",
    "            Z_activity = [(m,)]\n",
    "        \n",
    "        canvas.addActivity([(k,)], B_activity, Z_activity,\n",
    "                           spacetime=(0, k))\n",
    "    \n",
    "\n",
    "#\n",
    "# Display results\n",
    "#\n",
    "print(\"Output tensor Z (final)\")\n",
    "displayTensor(Z_M)\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dot Product - Skipping \"empty\" coordinates in A\n",
    "\n",
    "The following code sequence corresponds to an implementation of dot product where the hardware can traverse just the **non-empty** elements of the input tensor `A` and then only accesses the elements of `B` for the **coordinates** of those **non-empty** elements of `A`. This corresponds to the case where there is **skipping** of elements of `A`.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The code below uses the default `Fiber` iterator to obtain the **coordinates** and **payloads** of the **non-empty** elements of tensor `A`. \n",
    "\n",
    "- The cost of the reference to `B` using `Fiber.getPayload()` will vary based on the cost of finding a **payload** by **coordinates** for the specific format used for `B`.\n",
    "\n",
    "- As in the case above, the code in this cell assumes that the output tensor `Z` is in an uncompressed format.\n",
    "\n",
    "Observations:\n",
    "\n",
    "- The computation takes a number of cycles (and does reads and computes) proportional to the number of **non-empty** elements in `A`, i.e., `A`'s **occupancy**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Create the input/output tensors\n",
    "#\n",
    "K = getShape(tm, \"K\")\n",
    "M = 1\n",
    "\n",
    "A_K = tm.makeTensor(\"A\")\n",
    "B_K = tm.makeTensor(\"B\")\n",
    "Z_M = Tensor(name=\"Z\", rank_ids=[\"M\"], shape=[M])\n",
    "\n",
    "uncompressTensor(Z_M)\n",
    "\n",
    "#\n",
    "# Display the input tensors\n",
    "#\n",
    "print(\"Problem instance:\")\n",
    "print(f\"K: {K}\")\n",
    "print(f\"M: {M}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Input A\")\n",
    "displayTensor(A_K)\n",
    "print(\"Input B\")\n",
    "displayTensor(B_K)\n",
    "print(\"Output Z (initial)\")\n",
    "displayTensor(Z_M)\n",
    "\n",
    "#\n",
    "# Get the root fibers of each tensor\n",
    "#\n",
    "a_k = A_K.getRoot()\n",
    "b_k = B_K.getRoot()\n",
    "z_m = Z_M.getRoot()\n",
    "\n",
    "\n",
    "#\n",
    "# Animation bookkeeping\n",
    "#\n",
    "canvas = createCanvas(A_K, B_K, Z_M)\n",
    "\n",
    "#\n",
    "# Traverse the single element of the output shape\n",
    "#\n",
    "for m in range(M):\n",
    "    #\n",
    "    # Traverse non-empty elements of the tensor `A`\n",
    "    #\n",
    "    for k, a_val in a_k:\n",
    "        #\n",
    "        # Get value of `B` at non-zero coordinates of `A`\n",
    "        # and then do compute\n",
    "        #\n",
    "        b_val = b_k.getPayload(k)\n",
    "\n",
    "        z_m[m] += a_val * b_val\n",
    "\n",
    "        #\n",
    "        # Animation bookkeeping\n",
    "        #\n",
    "        canvas.addActivity([(k,)], [(k,)], [(m,)],\n",
    "                           spacetime=(0, k))\n",
    "\n",
    "#\n",
    "# Display results\n",
    "#\n",
    "print(\"Output tensor Z (final)\")\n",
    "displayTensor(Z_M)\n",
    "\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area\n",
    "\n",
    "For running alternative algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
